{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Logistic Regression mathematics in coding"
      ],
      "metadata": {
        "id": "FRbeadkzl4wE"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i_rJ59G1-qkc",
        "outputId": "05ae00a4-8b7f-4043-e07d-3de6bd96e7a4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration 0: Cost = 0.6931471805599453\n",
            "Iteration 100: Cost = 0.19610142026457208\n",
            "Iteration 200: Cost = 0.10984298685297385\n",
            "Iteration 300: Cost = 0.0755870487241721\n",
            "Iteration 400: Cost = 0.05746885820861871\n",
            "Iteration 500: Cost = 0.04631784069699418\n",
            "Iteration 600: Cost = 0.03878060970584242\n",
            "Iteration 700: Cost = 0.03335145848859831\n",
            "Iteration 800: Cost = 0.029256857148436077\n",
            "Iteration 900: Cost = 0.026059591713895623\n",
            "Predictions: [1 1]\n"
          ]
        }
      ],
      "source": [
        "#  libraries\n",
        "import numpy as np\n",
        "\n",
        "#  sigmoid function\n",
        "def sigmoid(z):\n",
        "    \"\"\"\n",
        "    Compute the sigmoid of z.\n",
        "    \"\"\"\n",
        "    return 1 / (1 + np.exp(-z))\n",
        "\n",
        "# cost function (Log Loss)\n",
        "def compute_cost(y, y_pred):\n",
        "    \"\"\"\n",
        "    Compute the logistic regression cost.\n",
        "    y: Actual labels (0 or 1)\n",
        "    y_pred: Predicted probabilities (between 0 and 1)\n",
        "    \"\"\"\n",
        "    m = len(y)\n",
        "    cost = -np.mean(y * np.log(y_pred) + (1 - y) * np.log(1 - y_pred))\n",
        "    return cost\n",
        "\n",
        "#   gradient descent\n",
        "def gradient_descent(X, y, w, b, learning_rate, num_iterations):\n",
        "    \"\"\"\n",
        "    Train logistic regression model using gradient descent.\n",
        "    X: Feature matrix\n",
        "    y: Labels\n",
        "    w: Weights (coefficients)\n",
        "    b: Bias term\n",
        "    learning_rate: Learning rate for gradient descent\n",
        "    num_iterations: Number of iterations\n",
        "    \"\"\"\n",
        "    m = X.shape[0]\n",
        "    for i in range(num_iterations):\n",
        "        # Compute the predictions\n",
        "        z = np.dot(X, w) + b\n",
        "        y_pred = sigmoid(z)\n",
        "\n",
        "        # Compute the gradients\n",
        "        dw = (1 / m) * np.dot(X.T, (y_pred - y))\n",
        "        db = (1 / m) * np.sum(y_pred - y)\n",
        "\n",
        "        # Update weights and bias\n",
        "        w -= learning_rate * dw\n",
        "        b -= learning_rate * db\n",
        "\n",
        "        # Print cost every 100 iterations (optional)\n",
        "        if i % 100 == 0:\n",
        "            cost = compute_cost(y, y_pred)\n",
        "            print(f\"Iteration {i}: Cost = {cost}\")\n",
        "\n",
        "    return w, b\n",
        "\n",
        "# Prediction\n",
        "def predict(X, w, b):\n",
        "    \"\"\"\n",
        "    Predict the class (0 or 1) for input data X.\n",
        "    X: Feature matrix\n",
        "    w: Weights\n",
        "    b: Bias\n",
        "    \"\"\"\n",
        "    z = np.dot(X, w) + b\n",
        "    y_pred = sigmoid(z)\n",
        "    predictions = (y_pred >= 0.5).astype(int)\n",
        "    return predictions\n",
        "\n",
        "#  dataset\n",
        "# Example dataset with 2 features\n",
        "X = np.array([[0.5, 1.5],\n",
        "              [1.0, 2.0],\n",
        "              [1.5, 0.5],\n",
        "              [2.0, 1.0],\n",
        "              [3.0, 3.5]])\n",
        "y = np.array([0, 0, 1, 1, 1])  # Labels (0 or 1)\n",
        "\n",
        "# Normalize the data (optional but recommended for better performance)\n",
        "X = (X - np.mean(X, axis=0)) / np.std(X, axis=0)\n",
        "\n",
        "# Initialize weights and bias\n",
        "num_features = X.shape[1]\n",
        "w = np.zeros(num_features)  # Initialize weights as zeros\n",
        "b = 0  # Initialize bias as zero\n",
        "\n",
        "# Train the model\n",
        "learning_rate = 0.1\n",
        "num_iterations = 1000\n",
        "w, b = gradient_descent(X, y, w, b, learning_rate, num_iterations)\n",
        "\n",
        "# Make predictions\n",
        "X_test = np.array([[1.5, 2.0], [2.5, 2.5]])  # Example test data\n",
        "X_test = (X_test - np.mean(X, axis=0)) / np.std(X, axis=0)  # Normalize test data\n",
        "predictions = predict(X_test, w, b)\n",
        "\n",
        "print(\"Predictions:\", predictions)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Experiments of Logistic Regression"
      ],
      "metadata": {
        "id": "cvsGwtzsqC6R"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "experiment 1"
      ],
      "metadata": {
        "id": "KYYEXY96qHCH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Dataset\n",
        "X = np.array([[15, 9.8, 1, 21],  # Habitable\n",
        "              [400, 3.7, 0, 0],   # Not habitable\n",
        "              [-100, 1.6, 0, 0],  # Not habitable\n",
        "              [20, 9.8, 1, 23],   # Habitable\n",
        "              [30, 24.8, 1, 10]]) # Not habitable\n",
        "y = np.array([1, 0, 0, 1, 0])  # Labels: 1 = Habitable, 0 = Not Habitable\n",
        "\n",
        "# Normalizing features\n",
        "X = (X - np.mean(X, axis=0)) / np.std(X, axis=0)\n",
        "\n",
        "# Initialize weights and bias\n",
        "w = np.zeros(X.shape[1])\n",
        "b = 0\n",
        "\n",
        "# Training the model\n",
        "learning_rate = 0.1\n",
        "num_iterations = 1000\n",
        "w, b = gradient_descent(X, y, w, b, learning_rate, num_iterations)\n",
        "\n",
        "# Test data\n",
        "X_test = np.array([[25, 9.8, 1, 22],  # Similar to Earth\n",
        "                   [300, 3.7, 0, 0]]) # Venus-like\n",
        "X_test = (X_test - np.mean(X, axis=0)) / np.std(X, axis=0)\n",
        "\n",
        "# Predictions\n",
        "predictions = predict(X_test, w, b)\n",
        "print(\"Space Exploration Predictions:\", predictions)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BNobcwtnqI5y",
        "outputId": "75b19efc-a61e-46ef-e310-1a10f68590f1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration 0: Cost = 0.6931471805599453\n",
            "Iteration 100: Cost = 0.11825943792799957\n",
            "Iteration 200: Cost = 0.0609186965449627\n",
            "Iteration 300: Cost = 0.040532652968367965\n",
            "Iteration 400: Cost = 0.030256491694355868\n",
            "Iteration 500: Cost = 0.02409894353472342\n",
            "Iteration 600: Cost = 0.020007911921016218\n",
            "Iteration 700: Cost = 0.01709662374334022\n",
            "Iteration 800: Cost = 0.014920876426395033\n",
            "Iteration 900: Cost = 0.013234072134995986\n",
            "Space Exploration Predictions: [1 0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Experiment2"
      ],
      "metadata": {
        "id": "X-r_tXdUqSv5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset\n",
        "X = np.array([[23, 5, 1, 1],  # Suspicious\n",
        "              [10, 0, 0, 0],  # Not suspicious\n",
        "              [2, 3, 1, 1],   # Suspicious\n",
        "              [14, 1, 0, 0],  # Not suspicious\n",
        "              [21, 4, 1, 0]]) # Suspicious\n",
        "y = np.array([1, 0, 1, 0, 1])  # Labels: 1 = Suspicious, 0 = Not Suspicious\n",
        "\n",
        "# Normalize and train\n",
        "X = (X - np.mean(X, axis=0)) / np.std(X, axis=0)\n",
        "w = np.zeros(X.shape[1])\n",
        "b = 0\n",
        "w, b = gradient_descent(X, y, w, b, learning_rate, num_iterations)\n",
        "\n",
        "# Test data\n",
        "X_test = np.array([[20, 2, 1, 1],  # Likely suspicious\n",
        "                   [8, 0, 0, 0]])  # Normal\n",
        "X_test = (X_test - np.mean(X, axis=0)) / np.std(X, axis=0)\n",
        "\n",
        "# Predictions\n",
        "predictions = predict(X_test, w, b)\n",
        "print(\"Hacking Predictions:\", predictions)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oa2pbzbtqUWC",
        "outputId": "ca2d8b8d-9aef-455a-eff5-dcf551a3e46e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration 0: Cost = 0.6931471805599453\n",
            "Iteration 100: Cost = 0.060210955948932686\n",
            "Iteration 200: Cost = 0.031105581072305856\n",
            "Iteration 300: Cost = 0.020941240708517644\n",
            "Iteration 400: Cost = 0.01577931928319315\n",
            "Iteration 500: Cost = 0.012658644313562914\n",
            "Iteration 600: Cost = 0.01056896790881666\n",
            "Iteration 700: Cost = 0.009071998743141348\n",
            "Iteration 800: Cost = 0.007946948176002873\n",
            "Iteration 900: Cost = 0.007070541772786891\n",
            "Hacking Predictions: [1 1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Experiment3"
      ],
      "metadata": {
        "id": "CJxS2UcLqbsb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset\n",
        "X = np.array([[12, 1, 1],  # Adaptive traits present\n",
        "              [3, 0, 1],   # No adaptive traits\n",
        "              [15, 1, 0],  # Adaptive traits present\n",
        "              [7, 0, 1],   # No adaptive traits\n",
        "              [10, 1, 1]]) # Adaptive traits present\n",
        "y = np.array([1, 0, 1, 0, 1])  # Labels: 1 = Adaptive traits, 0 = None\n",
        "\n",
        "# Normalize and train\n",
        "X = (X - np.mean(X, axis=0)) / np.std(X, axis=0)\n",
        "w = np.zeros(X.shape[1])\n",
        "b = 0\n",
        "w, b = gradient_descent(X, y, w, b, learning_rate, num_iterations)\n",
        "\n",
        "# Test data\n",
        "X_test = np.array([[8, 1, 1],  # Likely adaptive\n",
        "                   [4, 0, 0]]) # Non-adaptive\n",
        "X_test = (X_test - np.mean(X, axis=0)) / np.std(X, axis=0)\n",
        "\n",
        "# Predictions\n",
        "predictions = predict(X_test, w, b)\n",
        "print(\"Evolutionary Biology Predictions:\", predictions)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VOySPhHaqdpg",
        "outputId": "fcb0600e-a33a-4bfe-eae3-702ec02c58be"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration 0: Cost = 0.6931471805599453\n",
            "Iteration 100: Cost = 0.07613171443229241\n",
            "Iteration 200: Cost = 0.0396043618220428\n",
            "Iteration 300: Cost = 0.026726444864907734\n",
            "Iteration 400: Cost = 0.020169554451149135\n",
            "Iteration 500: Cost = 0.016200096360405546\n",
            "Iteration 600: Cost = 0.013539417512517726\n",
            "Iteration 700: Cost = 0.011631843657751497\n",
            "Iteration 800: Cost = 0.010197177170078862\n",
            "Iteration 900: Cost = 0.009078863263776802\n",
            "Evolutionary Biology Predictions: [1 1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Experiment 4"
      ],
      "metadata": {
        "id": "xgm1q90Qqh-W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset\n",
        "X = np.array([[130, 240, 1],  # Disease present\n",
        "              [120, 200, 0],  # No disease\n",
        "              [140, 250, 1],  # Disease present\n",
        "              [115, 180, 0],  # No disease\n",
        "              [135, 230, 1]]) # Disease present\n",
        "y = np.array([1, 0, 1, 0, 1])  # Labels: 1 = Disease, 0 = No Disease\n",
        "\n",
        "# Normalize and train\n",
        "X = (X - np.mean(X, axis=0)) / np.std(X, axis=0)\n",
        "w = np.zeros(X.shape[1])\n",
        "b = 0\n",
        "w, b = gradient_descent(X, y, w, b, learning_rate, num_iterations)\n",
        "\n",
        "# Test data\n",
        "X_test = np.array([[125, 220, 1],  # Likely disease\n",
        "                   [110, 190, 0]]) # Healthy\n",
        "X_test = (X_test - np.mean(X, axis=0)) / np.std(X, axis=0)\n",
        "\n",
        "# Predictions\n",
        "predictions = predict(X_test, w, b)\n",
        "print(\"Simple Biology Predictions:\", predictions)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "196OmDn9qjhs",
        "outputId": "7ee05632-8a72-4cae-fc5c-b931361f0ea3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration 0: Cost = 0.6931471805599453\n",
            "Iteration 100: Cost = 0.048966948497879234\n",
            "Iteration 200: Cost = 0.025217515812226497\n",
            "Iteration 300: Cost = 0.017019653912466244\n",
            "Iteration 400: Cost = 0.012860418638859516\n",
            "Iteration 500: Cost = 0.01034284039454739\n",
            "Iteration 600: Cost = 0.008654057048360515\n",
            "Iteration 700: Cost = 0.007442075706216874\n",
            "Iteration 800: Cost = 0.006529626887330923\n",
            "Iteration 900: Cost = 0.0058176886871188485\n",
            "Simple Biology Predictions: [1 1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "experiment5"
      ],
      "metadata": {
        "id": "5ZXKa-SGqtpB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset\n",
        "X = np.array([[200, 21, 1],  # Alien life present\n",
        "              [50, 0, 0],    # No alien life\n",
        "              [180, 19, 1],  # Alien life present\n",
        "              [30, 0, 0],    # No alien life\n",
        "              [210, 22, 1]]) # Alien life present\n",
        "y = np.array([1, 0, 1, 0, 1])  # Labels: 1 = Alien life, 0 = None\n",
        "\n",
        "# Normalize and train\n",
        "X = (X - np.mean(X, axis=0)) / np.std(X, axis=0)\n",
        "w = np.zeros(X.shape[1])\n",
        "b = 0\n",
        "w, b = gradient_descent(X, y, w, b, learning_rate, num_iterations)\n",
        "\n",
        "# Test data\n",
        "X_test = np.array([[190, 20, 1],  # Signs of life\n",
        "                   [20, 0, 0]])   # Barren\n",
        "X_test = (X_test - np.mean(X, axis=0)) / np.std(X, axis=0)\n",
        "\n",
        "# Predictions\n",
        "predictions = predict(X_test, w, b)\n",
        "print(\"Alien Life Predictions:\", predictions)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "24tbBVv-qvlH",
        "outputId": "69506f3f-c304-427a-b59b-60c2f5234118"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration 0: Cost = 0.6931471805599453\n",
            "Iteration 100: Cost = 0.03920355609795441\n",
            "Iteration 200: Cost = 0.01961389277894668\n",
            "Iteration 300: Cost = 0.013072921595764378\n",
            "Iteration 400: Cost = 0.009806451691185285\n",
            "Iteration 500: Cost = 0.007848433960815153\n",
            "Iteration 600: Cost = 0.006543855332144376\n",
            "Iteration 700: Cost = 0.005612312617777542\n",
            "Iteration 800: Cost = 0.004913751797574125\n",
            "Iteration 900: Cost = 0.004370432967097405\n",
            "Alien Life Predictions: [1 1]\n"
          ]
        }
      ]
    }
  ]
}