{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kpz15pmnPgD6"
      },
      "outputs": [],
      "source": [
        "# Importing required libraries\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Load dataset\n",
        "iris = load_iris()\n",
        "X, y = iris.data, iris.target\n",
        "\n",
        "# Splitting data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Create a Decision Tree classifier\n",
        "clf = DecisionTreeClassifier(criterion='gini', max_depth=3, random_state=42)\n",
        "\n",
        "# Train the model\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "# Test the model\n",
        "accuracy = clf.score(X_test, y_test)\n",
        "print(f\"Accuracy: {accuracy:.4f}\")\n",
        "\n",
        "# Visualizing the Decision Tree\n",
        "plt.figure(figsize=(15, 7))\n",
        "plot_tree(clf, feature_names=iris.feature_names, class_names=iris.target_names, filled=True)\n",
        "plt.title(\"Decision Tree Visualization\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Effect of Maximum Depth\n",
        "\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Generate dataset\n",
        "X, y = make_classification(n_samples=500, n_features=2, n_classes=2, random_state=42, n_clusters_per_class=1)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Train decision trees with varying depths\n",
        "depths = [1, 3, 5, 10]\n",
        "plt.figure(figsize=(12, 8))\n",
        "\n",
        "for i, depth in enumerate(depths):\n",
        "    model = DecisionTreeClassifier(max_depth=depth, random_state=42)\n",
        "    model.fit(X_train, y_train)\n",
        "\n",
        "    # Evaluate and plot decision boundary\n",
        "    y_pred = model.predict(X_test)\n",
        "    acc = accuracy_score(y_test, y_pred)\n",
        "    print(f\"Depth {depth}: Accuracy = {acc:.2f}\")\n",
        "\n",
        "    # Plot decision boundary\n",
        "    x_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n",
        "    y_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n",
        "    xx, yy = np.meshgrid(np.arange(x_min, x_max, 0.1), np.arange(y_min, y_max, 0.1))\n",
        "    Z = model.predict(np.c_[xx.ravel(), yy.ravel()])\n",
        "    Z = Z.reshape(xx.shape)\n",
        "\n",
        "    plt.subplot(2, 2, i + 1)\n",
        "    plt.contourf(xx, yy, Z, alpha=0.8, cmap='coolwarm')\n",
        "    plt.scatter(X[:, 0], X[:, 1], c=y, edgecolor='k', cmap='coolwarm')\n",
        "    plt.title(f\"Max Depth = {depth}\")\n",
        "    plt.xlabel(\"Feature 1\")\n",
        "    plt.ylabel(\"Feature 2\")\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "tbFzP27qP9p_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " # Decision Tree Classification on Simple Data\n",
        "\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# Generate synthetic dataset\n",
        "X, y = make_classification(n_samples=200, n_features=2, n_classes=2, random_state=42, n_clusters_per_class=1)\n",
        "\n",
        "# Train decision tree classifier\n",
        "model = DecisionTreeClassifier(max_depth=3, random_state=42)\n",
        "model.fit(X, y)\n",
        "\n",
        "# Plot decision boundary\n",
        "x_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n",
        "y_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n",
        "xx, yy = np.meshgrid(np.arange(x_min, x_max, 0.1), np.arange(y_min, y_max, 0.1))\n",
        "Z = model.predict(np.c_[xx.ravel(), yy.ravel()])\n",
        "Z = Z.reshape(xx.shape)\n",
        "\n",
        "plt.contourf(xx, yy, Z, alpha=0.8, cmap='coolwarm')\n",
        "plt.scatter(X[:, 0], X[:, 1], c=y, edgecolor='k', cmap='coolwarm')\n",
        "plt.title(\"Decision Tree Decision Boundary\")\n",
        "plt.xlabel(\"Feature 1\")\n",
        "plt.ylabel(\"Feature 2\")\n",
        "plt.show()\n",
        "\n",
        "# Plot tree structure\n",
        "plt.figure(figsize=(10, 6))\n",
        "plot_tree(model, filled=True, feature_names=[\"Feature 1\", \"Feature 2\"], class_names=[\"Class 0\", \"Class 1\"])\n",
        "plt.title(\"Decision Tree Structure\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "oVt8LX-2QGr-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Handling Imbalanced Classes\n",
        "\n",
        "from sklearn.metrics import ConfusionMatrixDisplay\n",
        "\n",
        "# Generate an imbalanced dataset\n",
        "X, y = make_classification(n_samples=1000, n_features=2, n_classes=2, weights=[0.9, 0.1], random_state=42)\n",
        "\n",
        "# Train decision tree\n",
        "model = DecisionTreeClassifier(random_state=42)\n",
        "model.fit(X, y)\n",
        "\n",
        "# Predict and plot confusion matrix\n",
        "y_pred = model.predict(X)\n",
        "ConfusionMatrixDisplay.from_estimator(model, X, y, cmap='Blues')\n",
        "plt.title(\"Confusion Matrix for Imbalanced Data\")\n",
        "plt.show()\n",
        "\n",
        "# Decision boundary for imbalanced data\n",
        "x_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n",
        "y_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n",
        "xx, yy = np.meshgrid(np.arange(x_min, x_max, 0.1), np.arange(y_min, y_max, 0.1))\n",
        "Z = model.predict(np.c_[xx.ravel(), yy.ravel()])\n",
        "Z = Z.reshape(xx.shape)\n",
        "\n",
        "plt.contourf(xx, yy, Z, alpha=0.8, cmap='coolwarm')\n",
        "plt.scatter(X[:, 0], X[:, 1], c=y, edgecolor='k', cmap='coolwarm')\n",
        "plt.title(\"Decision Tree Decision Boundary (Imbalanced Data)\")\n",
        "plt.xlabel(\"Feature 1\")\n",
        "plt.ylabel(\"Feature 2\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "5aHwwtxdQrtp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Feature Importance\n",
        "\n",
        "\n",
        "from sklearn.datasets import make_classification\n",
        "import pandas as pd\n",
        "\n",
        "# Generate a dataset with multiple features\n",
        "X, y = make_classification(n_samples=200, n_features=5, n_classes=2, random_state=42)\n",
        "feature_names = [f\"Feature {i+1}\" for i in range(X.shape[1])]\n",
        "\n",
        "# Train decision tree\n",
        "model = DecisionTreeClassifier(random_state=42)\n",
        "model.fit(X, y)\n",
        "\n",
        "# Extract feature importances\n",
        "importances = model.feature_importances_\n",
        "importance_df = pd.DataFrame({'Feature': feature_names, 'Importance': importances})\n",
        "importance_df = importance_df.sort_values(by='Importance', ascending=False)\n",
        "\n",
        "# Plot feature importances\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.bar(importance_df['Feature'], importance_df['Importance'], color='teal')\n",
        "plt.title(\"Feature Importance\")\n",
        "plt.xlabel(\"Features\")\n",
        "plt.ylabel(\"Importance Score\")\n",
        "plt.show()\n",
        "\n"
      ],
      "metadata": {
        "id": "vEp4s-f7Q3G0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **THE END.**"
      ],
      "metadata": {
        "id": "3d1EYuPBRHvb"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "9K3VE2MmRMfj"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}