{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nOD0V39Cvdsj"
      },
      "outputs": [],
      "source": [
        "def check_purity(data):\n",
        "    label_column = data[:, -1]\n",
        "    unique_classes = np.unique(label_column)\n",
        "    return len(unique_classes) == 1\n",
        "def classify_data(data):\n",
        "    label_column = data[:, -1]\n",
        "    unique_classes, counts_unique_classes = np.unique(label_column, return_counts=True)\n",
        "    index = counts_unique_classes.argmax()\n",
        "    return unique_classes[index]\n",
        "def get_potential_splits(data):\n",
        "    potential_splits = {}\n",
        "    _, n_columns = data.shape\n",
        "    for column_index in range(n_columns - 1):  # excluding the last column which is the label\n",
        "        values = data[:, column_index]\n",
        "        unique_values = np.unique(values)\n",
        "        potential_splits[column_index] = unique_values\n",
        "    return potential_splits\n",
        "def calculate_entropy(data):\n",
        "    label_column = data[:, -1]\n",
        "    _, counts = np.unique(label_column, return_counts=True)\n",
        "    probabilities = counts / counts.sum()\n",
        "    return sum(probabilities * -np.log2(probabilities))\n",
        "\n",
        "def calculate_overall_entropy(data_below, data_above):\n",
        "    n = len(data_below) + len(data_above)\n",
        "    p_data_below = len(data_below) / n\n",
        "    p_data_above = len(data_above) / n\n",
        "    return p_data_below * calculate_entropy(data_below) + p_data_above * calculate_entropy(data_above)\n",
        "def determine_best_split(data, potential_splits):\n",
        "    overall_entropy = 9999\n",
        "    for column_index in potential_splits:\n",
        "        for value in potential_splits[column_index]:\n",
        "            data_below, data_above = split_data(data, split_column=column_index, split_value=value)\n",
        "            current_overall_entropy = calculate_overall_entropy(data_below, data_above)\n",
        "            if current_overall_entropy <= overall_entropy:\n",
        "                overall_entropy = current_overall_entropy\n",
        "                best_split_column = column_index\n",
        "                best_split_value = value\n",
        "    return best_split_column, best_split_value\n",
        "def split_data(data, split_column, split_value):\n",
        "    split_column_values = data[:, split_column]\n",
        "    type_of_feature = FEATURE_TYPES[split_column]\n",
        "    if type_of_feature == \"continuous\":\n",
        "        data_below = data[split_column_values <= split_value]\n",
        "        data_above = data[split_column_values > split_value]\n",
        "    else:\n",
        "        data_below = data[split_column_values == split_value]\n",
        "        data_above = data[split_column_values != split_value]\n",
        "    return data_below, data_above\n",
        "def decision_tree_algorithm(df, counter=0, min_samples=2, max_depth=5):\n",
        "    if counter == 0:\n",
        "        global COLUMN_HEADERS, FEATURE_TYPES\n",
        "        COLUMN_HEADERS = df.columns\n",
        "        FEATURE_TYPES = determine_type_of_feature(df)\n",
        "        data = df.values\n",
        "    else:\n",
        "        data = df\n",
        "    if (check_purity(data)) or (len(data) < min_samples) or (counter == max_depth):\n",
        "        return classify_data(data)\n",
        "    else:\n",
        "        counter += 1\n",
        "        potential_splits = get_potential_splits(data)\n",
        "        split_column, split_value = determine_best_split(data, potential_splits)\n",
        "        data_below, data_above = split_data(data, split_column, split_value)\n",
        "        if len(data_below) == 0 or len(data_above) == 0:\n",
        "            return classify_data(data)\n",
        "        feature_name = COLUMN_HEADERS[split_column]\n",
        "        type_of_feature = FEATURE_TYPES[split_column]\n",
        "        if type_of_feature == \"continuous\":\n",
        "            question = \"{} <= {}\".format(feature_name, split_value)\n",
        "        else:\n",
        "            question = \"{} = {}\".format(feature_name, split_value)\n",
        "        sub_tree = {question: []}\n",
        "        yes_answer = decision_tree_algorithm(data_below, counter, min_samples, max_depth)\n",
        "        no_answer = decision_tree_algorithm(data_above, counter, min_samples, max_depth)\n",
        "        if yes_answer == no_answer:\n",
        "            sub_tree = yes_answer\n",
        "        else:\n",
        "            sub_tree[question].append(yes_answer)\n",
        "            sub_tree[question].append(no_answer)\n",
        "        return sub_tree\n",
        "def predict_example(example, tree):\n",
        "    question = list(tree.keys())[0]\n",
        "    feature_name, comparison_operator, value = question.split(\" \")\n",
        "    if comparison_operator == \"<=\":\n",
        "        if example[feature_name] <= float(value):\n",
        "            answer = tree[question][0]\n",
        "        else:\n",
        "            answer = tree[question][1]\n",
        "    else:\n",
        "        if str(example[feature_name]) == value:\n",
        "            answer = tree[question][0]\n",
        "        else:\n",
        "            answer = tree[question][1]\n",
        "    if not isinstance(answer, dict):\n",
        "        return answer\n",
        "    else:\n",
        "        return predict_example(example, answer)\n",
        "\n",
        "def decision_tree_predictions(test_df, tree):\n",
        "    return test_df.apply(predict_example, args=(tree,), axis=1)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Sample data\n",
        "data = {\n",
        "    'feature_1': [2.77, 1.72, 3.67, 3.96, 2.99, 7.49, 9.00, 7.44],\n",
        "    'feature_2': [1.78, 1.72, 2.81, 2.61, 2.14, 3.16, 3.29, 0.56],\n",
        "    'label': [0, 0, 0, 0, 0, 1, 1, 1]\n",
        "}\n",
        "\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Define determine_type_of_feature (This is a placeholder, you can define it based on your use case)\n",
        "def determine_type_of_feature(df):\n",
        "    return [\"continuous\"] * (df.shape[1] - 1)\n",
        "\n",
        "# Build the decision tree\n",
        "tree = decision_tree_algorithm(df, max_depth=3)\n",
        "print(\"Decision Tree:\", tree)\n",
        "\n",
        "# Predictions\n",
        "test_data = {\n",
        "    'feature_1': [4, 6, 1.5],\n",
        "    'feature_2': [2, 3, 1.5]\n",
        "}\n",
        "test_df = pd.DataFrame(test_data)\n",
        "predictions = decision_tree_predictions(test_df, tree)\n",
        "print(\"Predictions:\", predictions)\n"
      ],
      "metadata": {
        "id": "dEfcNxYWzdpV",
        "outputId": "0a4e7768-ef1c-43d6-85b4-e9808aa5043b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decision Tree: {'feature_1 <= 3.96': [0.0, 1.0]}\n",
            "Predictions: 0    1.0\n",
            "1    1.0\n",
            "2    0.0\n",
            "dtype: float64\n"
          ]
        }
      ]
    }
  ]
}